{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1e0cbb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T06:44:19.900699Z",
     "iopub.status.busy": "2023-02-05T06:44:19.900319Z",
     "iopub.status.idle": "2023-02-05T06:44:19.920765Z",
     "shell.execute_reply": "2023-02-05T06:44:19.919665Z",
     "shell.execute_reply.started": "2023-02-05T06:44:19.900617Z"
    },
    "papermill": {
     "duration": 0.011801,
     "end_time": "2023-02-27T09:51:06.856580",
     "exception": false,
     "start_time": "2023-02-27T09:51:06.844779",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Introduction\n",
    "\n",
    "This kernels uses the recent pip wheel of DALI for decoding dicoms using GPU. It works for all JPEG2000 and most of the JPEG-lossless formated images.\n",
    "\n",
    "The decoding work strongly is based on the kernels of Theo Viel (@theoviel) and David Austin (@tivfrvqhs5)\n",
    "\n",
    "***WARNING***: Allthough the GPU decoding works for all train images, a few of the JPEG-lossless formated DICOMS (TransferSyntaxUID == '1.2.840.10008.1.2.4.70') of the hidden test set cannot be decoded. So its crucial to have a CPU fallback in place so the notebook wont throw an exception in the submission re-run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbd7405",
   "metadata": {
    "papermill": {
     "duration": 0.010013,
     "end_time": "2023-02-27T09:51:06.877182",
     "exception": false,
     "start_time": "2023-02-27T09:51:06.867169",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ee0e08",
   "metadata": {
    "papermill": {
     "duration": 0.010402,
     "end_time": "2023-02-27T09:51:06.898066",
     "exception": false,
     "start_time": "2023-02-27T09:51:06.887664",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We start with installing pip requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6550423",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-02-27T09:51:06.922126Z",
     "iopub.status.busy": "2023-02-27T09:51:06.920788Z",
     "iopub.status.idle": "2023-02-27T09:52:40.315076Z",
     "shell.execute_reply": "2023-02-27T09:52:40.313412Z"
    },
    "papermill": {
     "duration": 93.410463,
     "end_time": "2023-02-27T09:52:40.319055",
     "exception": false,
     "start_time": "2023-02-27T09:51:06.908592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q timm==0.6.5 --no-index --find-links=/kaggle/input/rsna-bc-pip-requirements\n",
    "!pip install -q albumentations==1.2.1 --no-index --find-links=/kaggle/input/rsna-bc-pip-requirements\n",
    "!pip install -q pylibjpeg-libjpeg==1.3.1 --no-index --find-links=/kaggle/input/rsna-bc-pip-requirements\n",
    "!pip install -q pydicom==2.0.0 --no-index --find-links=/kaggle/input/rsna-bc-pip-requirements\n",
    "!pip install -q python-gdcm==3.0.20 --no-index --find-links=/kaggle/input/rsna-bc-pip-requirements\n",
    "!pip install -q dicomsdl==0.109.1 --no-index --find-links=/kaggle/input/rsna-bc-pip-requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd726a3",
   "metadata": {
    "papermill": {
     "duration": 0.011136,
     "end_time": "2023-02-27T09:52:40.341171",
     "exception": false,
     "start_time": "2023-02-27T09:52:40.330035",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Then we install the latest DALI packaging which we will use for GPU decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dcd9344",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T09:52:40.365978Z",
     "iopub.status.busy": "2023-02-27T09:52:40.365527Z",
     "iopub.status.idle": "2023-02-27T09:53:28.930913Z",
     "shell.execute_reply": "2023-02-27T09:53:28.929090Z"
    },
    "papermill": {
     "duration": 48.581967,
     "end_time": "2023-02-27T09:53:28.934437",
     "exception": false,
     "start_time": "2023-02-27T09:52:40.352470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q /kaggle/input/nvidia-dali-nightly-cuda110-1230dev/nvidia_dali_nightly_cuda110-1.23.0.dev20230203-7187866-py3-none-manylinux2014_x86_64.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f0674e",
   "metadata": {
    "papermill": {
     "duration": 0.011109,
     "end_time": "2023-02-27T09:53:28.957064",
     "exception": false,
     "start_time": "2023-02-27T09:53:28.945955",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next, we import all the packages we need and patch a function to allow for INT16 support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10eb170f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T09:53:28.983046Z",
     "iopub.status.busy": "2023-02-27T09:53:28.981759Z",
     "iopub.status.idle": "2023-02-27T09:53:36.109219Z",
     "shell.execute_reply": "2023-02-27T09:53:36.107831Z"
    },
    "papermill": {
     "duration": 7.144444,
     "end_time": "2023-02-27T09:53:36.113146",
     "exception": false,
     "start_time": "2023-02-27T09:53:28.968702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import timm\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "from copy import copy\n",
    "import gc\n",
    "import shutil \n",
    "\n",
    "import glob\n",
    "from scipy.special import expit\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "cv2.setNumThreads(0)\n",
    "\n",
    "import dicomsdl\n",
    "import pydicom\n",
    "from pydicom.filebase import DicomBytesIO\n",
    "\n",
    "from os.path import join\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing as mp\n",
    "\n",
    "from types import SimpleNamespace\n",
    "from typing import Any, Dict\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "\n",
    "import nvidia.dali.fn as fn\n",
    "import nvidia.dali.types as types\n",
    "from nvidia.dali import pipeline_def\n",
    "from nvidia.dali.types import DALIDataType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a27df7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T09:53:36.138193Z",
     "iopub.status.busy": "2023-02-27T09:53:36.137725Z",
     "iopub.status.idle": "2023-02-27T09:53:36.157740Z",
     "shell.execute_reply": "2023-02-27T09:53:36.156094Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.036633,
     "end_time": "2023-02-27T09:53:36.161184",
     "exception": false,
     "start_time": "2023-02-27T09:53:36.124551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#we need to patch DALI for Int16 support\n",
    "\n",
    "\n",
    "from nvidia.dali.backend import TensorGPU, TensorListGPU\n",
    "from nvidia.dali.pipeline import Pipeline\n",
    "import nvidia.dali.ops as ops\n",
    "from nvidia.dali import types\n",
    "from nvidia.dali.plugin.base_iterator import _DaliBaseIterator\n",
    "from nvidia.dali.plugin.base_iterator import LastBatchPolicy\n",
    "import torch\n",
    "import torch.utils.dlpack as torch_dlpack\n",
    "import ctypes\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import pydicom\n",
    "\n",
    "to_torch_type = {\n",
    "    types.DALIDataType.FLOAT:   torch.float32,\n",
    "    types.DALIDataType.FLOAT64: torch.float64,\n",
    "    types.DALIDataType.FLOAT16: torch.float16,\n",
    "    types.DALIDataType.UINT8:   torch.uint8,\n",
    "    types.DALIDataType.INT8:    torch.int8,\n",
    "    types.DALIDataType.UINT16:  torch.int16,\n",
    "    types.DALIDataType.INT16:   torch.int16,\n",
    "    types.DALIDataType.INT32:   torch.int32,\n",
    "    types.DALIDataType.INT64:   torch.int64\n",
    "}\n",
    "\n",
    "\n",
    "def feed_ndarray(dali_tensor, arr, cuda_stream=None):\n",
    "    \"\"\"\n",
    "    Copy contents of DALI tensor to PyTorch's Tensor.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    `dali_tensor` : nvidia.dali.backend.TensorCPU or nvidia.dali.backend.TensorGPU\n",
    "                    Tensor from which to copy\n",
    "    `arr` : torch.Tensor\n",
    "            Destination of the copy\n",
    "    `cuda_stream` : torch.cuda.Stream, cudaStream_t or any value that can be cast to cudaStream_t.\n",
    "                    CUDA stream to be used for the copy\n",
    "                    (if not provided, an internal user stream will be selected)\n",
    "                    In most cases, using pytorch's current stream is expected (for example,\n",
    "                    if we are copying to a tensor allocated with torch.zeros(...))\n",
    "    \"\"\"\n",
    "    dali_type = to_torch_type[dali_tensor.dtype]\n",
    "\n",
    "    assert dali_type == arr.dtype, (\"The element type of DALI Tensor/TensorList\"\n",
    "                                    \" doesn't match the element type of the target PyTorch Tensor: \"\n",
    "                                    \"{} vs {}\".format(dali_type, arr.dtype))\n",
    "    assert dali_tensor.shape() == list(arr.size()), \\\n",
    "        (\"Shapes do not match: DALI tensor has size {0}, but PyTorch Tensor has size {1}\".\n",
    "            format(dali_tensor.shape(), list(arr.size())))\n",
    "    cuda_stream = types._raw_cuda_stream(cuda_stream)\n",
    "\n",
    "    # turn raw int to a c void pointer\n",
    "    c_type_pointer = ctypes.c_void_p(arr.data_ptr())\n",
    "    if isinstance(dali_tensor, (TensorGPU, TensorListGPU)):\n",
    "        stream = None if cuda_stream is None else ctypes.c_void_p(cuda_stream)\n",
    "        dali_tensor.copy_to_external(c_type_pointer, stream, non_blocking=True)\n",
    "    else:\n",
    "        dali_tensor.copy_to_external(c_type_pointer)\n",
    "    return arr\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d96c9a",
   "metadata": {
    "papermill": {
     "duration": 0.011189,
     "end_time": "2023-02-27T09:53:36.183638",
     "exception": false,
     "start_time": "2023-02-27T09:53:36.172449",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next I set major variables which handle the public run and the re-run on the hidden test set, and also allow for simulating the size of the hidden test set by setting RAM_CHECK = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71c82ae0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T09:53:36.208547Z",
     "iopub.status.busy": "2023-02-27T09:53:36.208083Z",
     "iopub.status.idle": "2023-02-27T09:53:36.488131Z",
     "shell.execute_reply": "2023-02-27T09:53:36.486356Z"
    },
    "papermill": {
     "duration": 0.297288,
     "end_time": "2023-02-27T09:53:36.492261",
     "exception": false,
     "start_time": "2023-02-27T09:53:36.194973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>laterality</th>\n",
       "      <th>view</th>\n",
       "      <th>age</th>\n",
       "      <th>cancer</th>\n",
       "      <th>biopsy</th>\n",
       "      <th>invasive</th>\n",
       "      <th>BIRADS</th>\n",
       "      <th>implant</th>\n",
       "      <th>density</th>\n",
       "      <th>machine_id</th>\n",
       "      <th>difficult_negative_case</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>10006</td>\n",
       "      <td>462822612</td>\n",
       "      <td>L</td>\n",
       "      <td>CC</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10006</td>\n",
       "      <td>1459541791</td>\n",
       "      <td>L</td>\n",
       "      <td>MLO</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10006</td>\n",
       "      <td>1864590858</td>\n",
       "      <td>R</td>\n",
       "      <td>MLO</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>10006</td>\n",
       "      <td>1874946579</td>\n",
       "      <td>R</td>\n",
       "      <td>CC</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>10011</td>\n",
       "      <td>220375232</td>\n",
       "      <td>L</td>\n",
       "      <td>CC</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>2</td>\n",
       "      <td>10512</td>\n",
       "      <td>457122509</td>\n",
       "      <td>R</td>\n",
       "      <td>CC</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>2</td>\n",
       "      <td>10512</td>\n",
       "      <td>474818568</td>\n",
       "      <td>R</td>\n",
       "      <td>MLO</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>2</td>\n",
       "      <td>10514</td>\n",
       "      <td>1196389201</td>\n",
       "      <td>L</td>\n",
       "      <td>CC</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>2</td>\n",
       "      <td>10514</td>\n",
       "      <td>1887797144</td>\n",
       "      <td>L</td>\n",
       "      <td>MLO</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>2</td>\n",
       "      <td>10514</td>\n",
       "      <td>415339637</td>\n",
       "      <td>R</td>\n",
       "      <td>MLO</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     site_id  patient_id    image_id laterality view   age  cancer  biopsy  \\\n",
       "0          2       10006   462822612          L   CC  61.0       0       0   \n",
       "1          2       10006  1459541791          L  MLO  61.0       0       0   \n",
       "2          2       10006  1864590858          R  MLO  61.0       0       0   \n",
       "3          2       10006  1874946579          R   CC  61.0       0       0   \n",
       "4          2       10011   220375232          L   CC  55.0       0       0   \n",
       "..       ...         ...         ...        ...  ...   ...     ...     ...   \n",
       "495        2       10512   457122509          R   CC  40.0       0       0   \n",
       "496        2       10512   474818568          R  MLO  40.0       0       0   \n",
       "497        2       10514  1196389201          L   CC  68.0       0       0   \n",
       "498        2       10514  1887797144          L  MLO  68.0       0       0   \n",
       "499        2       10514   415339637          R  MLO  68.0       0       0   \n",
       "\n",
       "     invasive  BIRADS  implant density  machine_id  difficult_negative_case  \n",
       "0           0     NaN        0     NaN          29                    False  \n",
       "1           0     NaN        0     NaN          29                    False  \n",
       "2           0     NaN        0     NaN          29                    False  \n",
       "3           0     NaN        0     NaN          29                    False  \n",
       "4           0     0.0        0     NaN          21                     True  \n",
       "..        ...     ...      ...     ...         ...                      ...  \n",
       "495         0     NaN        0     NaN          29                    False  \n",
       "496         0     NaN        0     NaN          29                    False  \n",
       "497         0     NaN        0     NaN          48                    False  \n",
       "498         0     NaN        0     NaN          48                    False  \n",
       "499         0     NaN        0     NaN          48                    False  \n",
       "\n",
       "[500 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Params\n",
    "\n",
    "COMP_FOLDER = '/kaggle/input/rsna-breast-cancer-detection/'\n",
    "DATA_FOLDER = COMP_FOLDER + 'test_images/'\n",
    "\n",
    "sample_submission = pd.read_csv(COMP_FOLDER + 'sample_submission.csv')\n",
    "\n",
    "PUBLIC_RUN = len(sample_submission) == 2\n",
    "\n",
    "N_CORES = mp.cpu_count()\n",
    "MIXED_PRECISION = False\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "RAM_CHECK = True\n",
    "DEBUG = True\n",
    "\n",
    "test_df = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/test.csv')\n",
    "test_df['cancer'] = 0 #dummy value\n",
    "\n",
    "\n",
    "if PUBLIC_RUN is False:\n",
    "    RAM_CHECK = False\n",
    "    DEBUG = False\n",
    "\n",
    "if RAM_CHECK is True:\n",
    "    test_df = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/train.csv')\n",
    "    patient_filter = list(sorted((set(test_df.patient_id.unique()))))[:8000]\n",
    "    test_df = test_df[test_df.patient_id.isin(patient_filter)]\n",
    "    DATA_FOLDER = DATA_FOLDER.replace('test','train')\n",
    "\n",
    "if DEBUG is True:\n",
    "    test_df = test_df.head(500)\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d336096b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T09:53:36.518104Z",
     "iopub.status.busy": "2023-02-27T09:53:36.517617Z",
     "iopub.status.idle": "2023-02-27T09:53:36.527854Z",
     "shell.execute_reply": "2023-02-27T09:53:36.525859Z"
    },
    "papermill": {
     "duration": 0.027153,
     "end_time": "2023-02-27T09:53:36.531257",
     "exception": false,
     "start_time": "2023-02-27T09:53:36.504104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len df : 500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Len df : {len(test_df)}')\n",
    "test_df['patient_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18a5327c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T09:53:36.557586Z",
     "iopub.status.busy": "2023-02-27T09:53:36.556762Z",
     "iopub.status.idle": "2023-02-27T09:53:36.567550Z",
     "shell.execute_reply": "2023-02-27T09:53:36.566248Z"
    },
    "papermill": {
     "duration": 0.027486,
     "end_time": "2023-02-27T09:53:36.570503",
     "exception": false,
     "start_time": "2023-02-27T09:53:36.543017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df[\"fns\"] = test_df['patient_id'].astype(str) + '/' + test_df['image_id'].astype(str) + '.dcm'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8e829a",
   "metadata": {
    "papermill": {
     "duration": 0.012114,
     "end_time": "2023-02-27T09:53:36.594638",
     "exception": false,
     "start_time": "2023-02-27T09:53:36.582524",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next, we define the function for GPU-based decoding using DALI and processing the dicom images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f1d46a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T09:53:36.621225Z",
     "iopub.status.busy": "2023-02-27T09:53:36.620771Z",
     "iopub.status.idle": "2023-02-27T09:53:36.642087Z",
     "shell.execute_reply": "2023-02-27T09:53:36.640789Z"
    },
    "papermill": {
     "duration": 0.038677,
     "end_time": "2023-02-27T09:53:36.645167",
     "exception": false,
     "start_time": "2023-02-27T09:53:36.606490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_dicom_to_jpg(file, save_folder=\"\"):\n",
    "    patient = file.split('/')[-2]\n",
    "    image = file.split('/')[-1][:-4]\n",
    "    dcmfile = pydicom.dcmread(file)\n",
    "\n",
    "    if dcmfile.file_meta.TransferSyntaxUID == '1.2.840.10008.1.2.4.90':\n",
    "        with open(file, 'rb') as fp:\n",
    "            raw = DicomBytesIO(fp.read())\n",
    "            ds = pydicom.dcmread(raw)\n",
    "        offset = ds.PixelData.find(b\"\\x00\\x00\\x00\\x0C\")  #<---- the jpeg2000 header info we're looking for\n",
    "        hackedbitstream = bytearray()\n",
    "        hackedbitstream.extend(ds.PixelData[offset:])\n",
    "        with open(save_folder + f\"{patient}_{image}.jpg\", \"wb\") as binary_file:\n",
    "            binary_file.write(hackedbitstream)\n",
    "            \n",
    "    if dcmfile.file_meta.TransferSyntaxUID == '1.2.840.10008.1.2.4.70':\n",
    "        with open(file, 'rb') as fp:\n",
    "            raw = DicomBytesIO(fp.read())\n",
    "            ds = pydicom.dcmread(raw)\n",
    "        offset = ds.PixelData.find(b\"\\xff\\xd8\\xff\\xe0\")  #<---- the jpeg lossless header info we're looking for\n",
    "        hackedbitstream = bytearray()\n",
    "        hackedbitstream.extend(ds.PixelData[offset:])\n",
    "        with open(save_folder + f\"{patient}_{image}.jpg\", \"wb\") as binary_file:\n",
    "            binary_file.write(hackedbitstream)\n",
    "\n",
    "            \n",
    "@pipeline_def\n",
    "def jpg_decode_pipeline(jpgfiles):\n",
    "    jpegs, _ = fn.readers.file(files=jpgfiles)\n",
    "    images = fn.experimental.decoders.image(jpegs, device='mixed', output_type=types.ANY_DATA, dtype=DALIDataType.UINT16)\n",
    "    return images\n",
    "\n",
    "def parse_window_element(elem):\n",
    "    if type(elem)==list:\n",
    "        return float(elem[0])\n",
    "    if type(elem)==str:\n",
    "        return float(elem)\n",
    "    if type(elem)==float:\n",
    "        return elem\n",
    "    if type(elem)==pydicom.dataelem.DataElement:\n",
    "        try:\n",
    "            return float(elem[0])\n",
    "        except:\n",
    "            return float(elem.value)\n",
    "    return None\n",
    "\n",
    "def linear_window(data, center, width):\n",
    "    lower, upper = center - width // 2, center + width // 2\n",
    "    data = torch.clamp(data, min=lower, max=upper)\n",
    "    return data \n",
    "\n",
    "def process_dicom(img, dicom):\n",
    "    try:\n",
    "        invert = getattr(dicom, \"PhotometricInterpretation\", None) == \"MONOCHROME1\"\n",
    "    except:\n",
    "        invert = False\n",
    "        \n",
    "    center = parse_window_element(dicom[\"WindowCenter\"]) \n",
    "    width = parse_window_element(dicom[\"WindowWidth\"])\n",
    "        \n",
    "    if (center is not None) & (width is not None):\n",
    "        img = linear_window(img, center, width)\n",
    "\n",
    "    img = (img - img.min()) / (img.max() - img.min())\n",
    "    if invert:\n",
    "        img = 1 - img\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2739115",
   "metadata": {
    "papermill": {
     "duration": 0.011761,
     "end_time": "2023-02-27T09:53:36.668579",
     "exception": false,
     "start_time": "2023-02-27T09:53:36.656818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "620f1daf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T09:53:36.694646Z",
     "iopub.status.busy": "2023-02-27T09:53:36.693693Z",
     "iopub.status.idle": "2023-02-27T09:53:36.702473Z",
     "shell.execute_reply": "2023-02-27T09:53:36.700871Z"
    },
    "papermill": {
     "duration": 0.026241,
     "end_time": "2023-02-27T09:53:36.706662",
     "exception": false,
     "start_time": "2023-02-27T09:53:36.680421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cfg = SimpleNamespace(**{})\n",
    "cfg.img_size = 1024\n",
    "cfg.backbone = 'seresnext50_32x4d'\n",
    "cfg.pretrained=False\n",
    "cfg.in_channels = 1\n",
    "cfg.classes = ['cancer']\n",
    "cfg.batch_size = 16  #8\n",
    "cfg.data_folder = \"/tmp/output/\"\n",
    "cfg.val_aug = A.CenterCrop(always_apply=False, p=1.0, height=cfg.img_size, width=cfg.img_size)\n",
    "cfg.device = DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fd69b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T07:14:35.534267Z",
     "iopub.status.busy": "2023-02-05T07:14:35.533224Z",
     "iopub.status.idle": "2023-02-05T07:14:35.545681Z",
     "shell.execute_reply": "2023-02-05T07:14:35.544691Z",
     "shell.execute_reply.started": "2023-02-05T07:14:35.534231Z"
    },
    "papermill": {
     "duration": 0.011696,
     "end_time": "2023-02-27T09:53:36.729968",
     "exception": false,
     "start_time": "2023-02-27T09:53:36.718272",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We will process the dicoms in chunks so the disk space does not become an issue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cee3d1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T09:53:36.756115Z",
     "iopub.status.busy": "2023-02-27T09:53:36.754935Z",
     "iopub.status.idle": "2023-02-27T09:53:36.765005Z",
     "shell.execute_reply": "2023-02-27T09:53:36.763726Z"
    },
    "papermill": {
     "duration": 0.026341,
     "end_time": "2023-02-27T09:53:36.768071",
     "exception": false,
     "start_time": "2023-02-27T09:53:36.741730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SAVE_SIZE = int(cfg.img_size * 1.125)\n",
    "SAVE_FOLDER = cfg.data_folder\n",
    "os.makedirs(SAVE_FOLDER, exist_ok=True)\n",
    "N_CHUNKS = len(test_df[\"fns\"]) // 2000 if len(test_df[\"fns\"]) > 2000 else 1\n",
    "CHUNKS = [(len(test_df[\"fns\"]) / N_CHUNKS * k, len(test_df[\"fns\"]) / N_CHUNKS * (k + 1)) for k in range(N_CHUNKS)]\n",
    "CHUNKS = np.array(CHUNKS).astype(int)\n",
    "JPG_FOLDER = \"/tmp/jpg/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dae80cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T09:53:36.794199Z",
     "iopub.status.busy": "2023-02-27T09:53:36.793134Z",
     "iopub.status.idle": "2023-02-27T09:55:26.080642Z",
     "shell.execute_reply": "2023-02-27T09:55:26.078028Z"
    },
    "papermill": {
     "duration": 109.304738,
     "end_time": "2023-02-27T09:55:26.084491",
     "exception": false,
     "start_time": "2023-02-27T09:53:36.779753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 0 of 1 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:17<00:00,  6.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DALI Raw image load complete\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for ttt, chunk in enumerate(CHUNKS):\n",
    "    print(f'chunk {ttt} of {len(CHUNKS)} chunks')\n",
    "    os.makedirs(JPG_FOLDER, exist_ok=True)\n",
    "\n",
    "    _ = Parallel(n_jobs=2)(\n",
    "        delayed(convert_dicom_to_jpg)(f'{DATA_FOLDER}/{img}', save_folder=JPG_FOLDER)\n",
    "        for img in test_df[\"fns\"].tolist()[chunk[0]: chunk[1]]\n",
    "    )\n",
    "    \n",
    "    jpgfiles = glob.glob(JPG_FOLDER + \"*.jpg\")\n",
    "\n",
    "\n",
    "    pipe = jpg_decode_pipeline(jpgfiles, batch_size=1, num_threads=2, device_id=0)\n",
    "    pipe.build()\n",
    "\n",
    "    for i, f in enumerate(tqdm(jpgfiles)):\n",
    "        \n",
    "        patient, dicom_id = f.split('/')[-1][:-4].split('_')\n",
    "        dicom = pydicom.dcmread(DATA_FOLDER + f\"/{patient}/{dicom_id}.dcm\")\n",
    "        try:\n",
    "            out = pipe.run()\n",
    "            # Dali -> Torch\n",
    "            img = out[0][0]\n",
    "            img_torch = torch.empty(img.shape(), dtype=torch.int16, device=\"cuda\")\n",
    "            feed_ndarray(img, img_torch, cuda_stream=torch.cuda.current_stream(device=0))\n",
    "            img = img_torch.float()\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "            #apply dicom preprocessing\n",
    "            img = process_dicom(img, dicom)\n",
    "\n",
    "            #resize the torch image\n",
    "            img = F.interpolate(img.view(1, 1, img.size(0), img.size(1)), (SAVE_SIZE, SAVE_SIZE), mode=\"bilinear\")[0, 0]\n",
    "\n",
    "            img = (img * 255).clip(0,255).to(torch.uint8).cpu().numpy()\n",
    "            out_file_name = SAVE_FOLDER + f\"{patient}_{dicom_id}.png\"\n",
    "            cv2.imwrite(out_file_name, img)\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(i, e)\n",
    "            pipe = jpg_decode_pipeline(jpgfiles[i+1:], batch_size=1, num_threads=2, device_id=0)\n",
    "            pipe.build()\n",
    "            continue\n",
    "\n",
    "    shutil.rmtree(JPG_FOLDER)\n",
    "print(f'DALI Raw image load complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7498b2bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T09:55:26.154416Z",
     "iopub.status.busy": "2023-02-27T09:55:26.152057Z",
     "iopub.status.idle": "2023-02-27T09:55:26.163522Z",
     "shell.execute_reply": "2023-02-27T09:55:26.161995Z"
    },
    "papermill": {
     "duration": 0.050148,
     "end_time": "2023-02-27T09:55:26.167616",
     "exception": false,
     "start_time": "2023-02-27T09:55:26.117468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image on disk count : 500\n"
     ]
    }
   ],
   "source": [
    "fns = glob.glob(f'{SAVE_FOLDER}/*.png')\n",
    "n_saved = len(fns)\n",
    "print(f'Image on disk count : {n_saved}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f160ffdb",
   "metadata": {
    "papermill": {
     "duration": 0.033226,
     "end_time": "2023-02-27T09:55:26.234232",
     "exception": false,
     "start_time": "2023-02-27T09:55:26.201006",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "A few hidden test set images might not be decoded via DALI, so we fallback to CPU for those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc2f3fe8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T09:55:26.302676Z",
     "iopub.status.busy": "2023-02-27T09:55:26.302214Z",
     "iopub.status.idle": "2023-02-27T09:55:26.316131Z",
     "shell.execute_reply": "2023-02-27T09:55:26.314654Z"
    },
    "papermill": {
     "duration": 0.051608,
     "end_time": "2023-02-27T09:55:26.319037",
     "exception": false,
     "start_time": "2023-02-27T09:55:26.267429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_processed_files = [fn.split('/')[-1].replace('_','/').replace('png','dcm') for fn in fns]\n",
    "to_process = [f for f in test_df[\"fns\"].values if f not in gpu_processed_files]\n",
    "len(gpu_processed_files), len(to_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5f36641",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T09:55:26.389572Z",
     "iopub.status.busy": "2023-02-27T09:55:26.389088Z",
     "iopub.status.idle": "2023-02-27T09:55:26.398957Z",
     "shell.execute_reply": "2023-02-27T09:55:26.397494Z"
    },
    "papermill": {
     "duration": 0.049007,
     "end_time": "2023-02-27T09:55:26.401837",
     "exception": false,
     "start_time": "2023-02-27T09:55:26.352830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def process(f, save_folder=\"\"):\n",
    "    patient = f.split('/')[-2]\n",
    "    dicom_id = f.split('/')[-1][:-4]\n",
    "    \n",
    "    dicom = dicomsdl.open(f)\n",
    "    img = dicom.pixelData()\n",
    "    img = torch.from_numpy(img)\n",
    "    img = process_dicom(img, dicom)\n",
    "    \n",
    "    img = F.interpolate(img.view(1, 1, img.size(0), img.size(1)), (SAVE_SIZE, SAVE_SIZE), mode=\"bilinear\")[0, 0]\n",
    "\n",
    "    img = (img * 255).clip(0,255).to(torch.uint8).cpu().numpy()\n",
    "    out_file_name = SAVE_FOLDER + f\"{patient}_{dicom_id}.png\"\n",
    "    cv2.imwrite(out_file_name, img)\n",
    "    return out_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fabcda9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T09:55:26.471585Z",
     "iopub.status.busy": "2023-02-27T09:55:26.470373Z",
     "iopub.status.idle": "2023-02-27T09:55:26.491274Z",
     "shell.execute_reply": "2023-02-27T09:55:26.489543Z"
    },
    "papermill": {
     "duration": 0.058815,
     "end_time": "2023-02-27T09:55:26.494711",
     "exception": false,
     "start_time": "2023-02-27T09:55:26.435896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Raw image load complete with 0 loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cpu_processed_filenames = Parallel(n_jobs=2)(\n",
    "    delayed(process)(f'{DATA_FOLDER}/{img}', save_folder=SAVE_FOLDER)\n",
    "    for img in tqdm(to_process)\n",
    ")\n",
    "cpu_processed_filenames = [f for f in cpu_processed_filenames if f]\n",
    "print(f'CPU Raw image load complete with {len(cpu_processed_filenames)} loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a4599a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T09:55:26.563105Z",
     "iopub.status.busy": "2023-02-27T09:55:26.562663Z",
     "iopub.status.idle": "2023-02-27T09:55:26.828667Z",
     "shell.execute_reply": "2023-02-27T09:55:26.827313Z"
    },
    "papermill": {
     "duration": 0.303786,
     "end_time": "2023-02-27T09:55:26.831671",
     "exception": false,
     "start_time": "2023-02-27T09:55:26.527885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e2ae7eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T09:55:26.923211Z",
     "iopub.status.busy": "2023-02-27T09:55:26.922637Z",
     "iopub.status.idle": "2023-02-27T09:55:26.933101Z",
     "shell.execute_reply": "2023-02-27T09:55:26.931021Z"
    },
    "papermill": {
     "duration": 0.049286,
     "end_time": "2023-02-27T09:55:26.936911",
     "exception": false,
     "start_time": "2023-02-27T09:55:26.887625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image on disk count : 500\n"
     ]
    }
   ],
   "source": [
    "n_saved = len(glob.glob(f'{SAVE_FOLDER}/*.png'))\n",
    "print(f'Image on disk count : {n_saved}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92af602c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T09:55:27.006323Z",
     "iopub.status.busy": "2023-02-27T09:55:27.005117Z",
     "iopub.status.idle": "2023-02-27T09:55:27.011752Z",
     "shell.execute_reply": "2023-02-27T09:55:27.010475Z"
    },
    "papermill": {
     "duration": 0.044695,
     "end_time": "2023-02-27T09:55:27.014965",
     "exception": false,
     "start_time": "2023-02-27T09:55:26.970270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert n_saved == len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1969ca25",
   "metadata": {
    "papermill": {
     "duration": 0.03404,
     "end_time": "2023-02-27T09:55:27.083680",
     "exception": false,
     "start_time": "2023-02-27T09:55:27.049640",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We finished with preprocessing all the dicoms to images. So next, we set-up the dataloading and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a333dbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T09:55:27.152164Z",
     "iopub.status.busy": "2023-02-27T09:55:27.151728Z",
     "iopub.status.idle": "2023-02-27T09:55:27.168247Z",
     "shell.execute_reply": "2023-02-27T09:55:27.166935Z"
    },
    "papermill": {
     "duration": 0.054363,
     "end_time": "2023-02-27T09:55:27.171200",
     "exception": false,
     "start_time": "2023-02-27T09:55:27.116837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def batch_to_device(batch, device):\n",
    "    batch_dict = {key: batch[key].to(device) for key in batch}\n",
    "    return batch_dict\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, cfg, aug):\n",
    "\n",
    "        self.cfg = cfg\n",
    "        self.df = df.copy()\n",
    "        self.df = self.df[self.df['image_id'].astype(str) != '1942326353']\n",
    "        self.labels = self.df[self.cfg.classes].values\n",
    "        self.df[\"fns\"] = self.df['patient_id'].astype(str) + '_' + self.df['image_id'].astype(str) + '.png'\n",
    "        self.fns = self.df[\"fns\"].astype(str).values\n",
    "        self.aug = aug\n",
    "        self.data_folder = cfg.data_folder\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        img = self.load_one(idx)\n",
    "\n",
    "        if self.aug:\n",
    "            img = self.augment(img)\n",
    "\n",
    "        img = self.normalize_img(img)\n",
    "        torch_img = torch.tensor(img).float().permute(2,0,1)\n",
    "        \n",
    "        feature_dict = {\n",
    "            \"input\": torch_img,\n",
    "            \"target\": torch.tensor(label),\n",
    "        }\n",
    "        return feature_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fns)\n",
    "\n",
    "    def load_one(self, idx):\n",
    "        path = self.data_folder + self.fns[idx]\n",
    "        try:\n",
    "            img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "            shape = img.shape\n",
    "            if len(img.shape) == 2:\n",
    "                img = img[:,:,None]\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        return img\n",
    "\n",
    "    def augment(self, img):\n",
    "        img = img.astype(np.float32)\n",
    "        transformed = self.aug(image=img)\n",
    "        trans_img = transformed[\"image\"]\n",
    "        return trans_img\n",
    "\n",
    "    def normalize_img(self, img):\n",
    "        img = img / 255\n",
    "        return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a41bc507",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T09:55:27.241651Z",
     "iopub.status.busy": "2023-02-27T09:55:27.240403Z",
     "iopub.status.idle": "2023-02-27T09:55:27.257615Z",
     "shell.execute_reply": "2023-02-27T09:55:27.256178Z"
    },
    "papermill": {
     "duration": 0.055914,
     "end_time": "2023-02-27T09:55:27.260594",
     "exception": false,
     "start_time": "2023-02-27T09:55:27.204680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gem(x, p=5, eps=1e-5):\n",
    "    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1.0 / p)\n",
    "\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=5, eps=1e-5, p_trainable=False):\n",
    "        super(GeM, self).__init__()\n",
    "        if p_trainable:\n",
    "            self.p = Parameter(torch.ones(1) * p)\n",
    "        else:\n",
    "            self.p = p\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        ret = gem(x, p=self.p, eps=self.eps)\n",
    "        return ret\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (self.__class__.__name__  + f\"(p={self.p.data.tolist()[0]:.4f},eps={self.eps})\")\n",
    "\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, cfg: Any):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.cfg = cfg\n",
    "        self.n_classes = len(cfg.classes)\n",
    "        self.backbone = timm.create_model(cfg.backbone, \n",
    "                                          pretrained=cfg.pretrained, \n",
    "                                          num_classes=0, \n",
    "                                          global_pool=\"\", \n",
    "                                          in_chans=self.cfg.in_channels)\n",
    "    \n",
    "        backbone_out = self.backbone.feature_info[-1]['num_chs']\n",
    "\n",
    "        self.global_pool = GeM(p_trainable=False)\n",
    "        self.head = torch.nn.Linear(backbone_out, self.n_classes)\n",
    "        self.loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, batch):\n",
    "\n",
    "        x = batch['input']\n",
    "\n",
    "        x = self.backbone(x)\n",
    "        x = self.global_pool(x)\n",
    "        x = x[:,:,0,0]\n",
    "\n",
    "        logits = self.head(x)\n",
    "        \n",
    "        \n",
    "        outputs = {}\n",
    "        \n",
    "        \n",
    "        if self.training:\n",
    "            loss = self.loss_fn(logits,batch[\"target\"].float())\n",
    "            outputs['loss'] = loss\n",
    "        else:\n",
    "            outputs[\"logits\"] = logits\n",
    "        \n",
    " \n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0b894c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T09:55:27.329579Z",
     "iopub.status.busy": "2023-02-27T09:55:27.328520Z",
     "iopub.status.idle": "2023-02-27T09:55:27.338733Z",
     "shell.execute_reply": "2023-02-27T09:55:27.337388Z"
    },
    "papermill": {
     "duration": 0.047753,
     "end_time": "2023-02-27T09:55:27.341449",
     "exception": false,
     "start_time": "2023-02-27T09:55:27.293696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dl(test_df, cfg):\n",
    "\n",
    "    test_ds = CustomDataset(test_df, cfg, cfg.val_aug)\n",
    "    test_dl = DataLoader(test_ds, shuffle=False, batch_size=cfg.batch_size, num_workers=N_CORES, pin_memory=True)\n",
    "\n",
    "    return test_dl, batch_to_device\n",
    "\n",
    "def get_state_dict(sd_fp):\n",
    "    sd = torch.load(sd_fp, map_location=\"cpu\")['model']\n",
    "    sd = {k.replace(\"module.\", \"\"):v for k,v in sd.items()}\n",
    "    return sd\n",
    "\n",
    "def get_nets(cfg,state_dicts):\n",
    "\n",
    "    nets = []\n",
    "\n",
    "    for i,state_dict in enumerate(state_dicts):\n",
    "        net = Net(cfg).eval().to(DEVICE)\n",
    "        print(\"loading dict\")\n",
    "        sd = get_state_dict(state_dict)\n",
    "        net.load_state_dict(sd, strict=True)\n",
    "        nets += [net]\n",
    "        del sd\n",
    "        gc.collect()\n",
    "    return nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "774990eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T09:55:27.414501Z",
     "iopub.status.busy": "2023-02-27T09:55:27.413250Z",
     "iopub.status.idle": "2023-02-27T09:55:27.430815Z",
     "shell.execute_reply": "2023-02-27T09:55:27.429364Z"
    },
    "papermill": {
     "duration": 0.055285,
     "end_time": "2023-02-27T09:55:27.433873",
     "exception": false,
     "start_time": "2023-02-27T09:55:27.378588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_dl, batch_to_device = get_dl(test_df, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a89c837e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T09:55:27.502674Z",
     "iopub.status.busy": "2023-02-27T09:55:27.501472Z",
     "iopub.status.idle": "2023-02-27T09:55:36.269332Z",
     "shell.execute_reply": "2023-02-27T09:55:36.268033Z"
    },
    "papermill": {
     "duration": 8.806102,
     "end_time": "2023-02-27T09:55:36.273064",
     "exception": false,
     "start_time": "2023-02-27T09:55:27.466962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/kaggle/input/rsna-seresnext50-5fold/checkpoint_last_seed298515.pth', '/kaggle/input/rsna-seresnext50-5fold/checkpoint_last_seed334760.pth', '/kaggle/input/rsna-seresnext50-5fold/checkpoint_last_seed607282.pth', '/kaggle/input/rsna-seresnext50-5fold/checkpoint_last_seed758935.pth', '/kaggle/input/rsna-seresnext50-5fold/checkpoint_last_seed779477.pth']\n",
      "loading dict\n",
      "loading dict\n",
      "loading dict\n",
      "loading dict\n",
      "loading dict\n"
     ]
    }
   ],
   "source": [
    "state_dicts = sorted(glob.glob('/kaggle/input/rsna-seresnext50-5fold/check*.pth'))\n",
    "print(state_dicts)\n",
    "\n",
    "nets = get_nets(cfg,state_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f897fc3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T09:55:36.343937Z",
     "iopub.status.busy": "2023-02-27T09:55:36.343471Z",
     "iopub.status.idle": "2023-02-27T09:55:36.350859Z",
     "shell.execute_reply": "2023-02-27T09:55:36.349352Z"
    },
    "papermill": {
     "duration": 0.047642,
     "end_time": "2023-02-27T09:55:36.355177",
     "exception": false,
     "start_time": "2023-02-27T09:55:36.307535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader length : 500\n"
     ]
    }
   ],
   "source": [
    "print(f'Dataloader length : {len(sub_dl.dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "29a39f3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T09:55:36.429542Z",
     "iopub.status.busy": "2023-02-27T09:55:36.429023Z",
     "iopub.status.idle": "2023-02-27T09:58:16.914604Z",
     "shell.execute_reply": "2023-02-27T09:58:16.912737Z"
    },
    "papermill": {
     "duration": 160.525154,
     "end_time": "2023-02-27T09:58:16.917907",
     "exception": false,
     "start_time": "2023-02-27T09:55:36.392753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [02:40<00:00,  5.01s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "\n",
    "    preds = [[] for i in range(len(nets))]\n",
    "    for batch in tqdm(sub_dl):\n",
    "        batch = batch_to_device(batch, cfg.device)\n",
    "        for i, net in enumerate(nets):\n",
    "            logits = net(batch)['logits'].sigmoid().float().detach().cpu().numpy()\n",
    "            preds[i] += [logits]\n",
    "            \n",
    "preds = np.array([np.concatenate(p, axis=0) for p in preds])\n",
    "preds = preds.mean(0) #average fold predictions\n",
    "preds = preds[:,0]\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7bfc78b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T09:58:16.996517Z",
     "iopub.status.busy": "2023-02-27T09:58:16.995112Z",
     "iopub.status.idle": "2023-02-27T09:58:17.005575Z",
     "shell.execute_reply": "2023-02-27T09:58:17.003973Z"
    },
    "papermill": {
     "duration": 0.053811,
     "end_time": "2023-02-27T09:58:17.009920",
     "exception": false,
     "start_time": "2023-02-27T09:58:16.956109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c277d30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T09:58:17.086173Z",
     "iopub.status.busy": "2023-02-27T09:58:17.085709Z",
     "iopub.status.idle": "2023-02-27T09:58:17.113197Z",
     "shell.execute_reply": "2023-02-27T09:58:17.111794Z"
    },
    "papermill": {
     "duration": 0.069328,
     "end_time": "2023-02-27T09:58:17.116564",
     "exception": false,
     "start_time": "2023-02-27T09:58:17.047236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "patient_id = sub_dl.dataset.df['patient_id'].values\n",
    "laterality = sub_dl.dataset.df['laterality'].values\n",
    "\n",
    "prediction_id = [f'{i}_{j}' for i,j in  zip(patient_id, laterality)]\n",
    "\n",
    "pred_df = pd.DataFrame({'prediction_id': prediction_id, 'cancer_raw': preds})\n",
    "\n",
    "#aggregate by prediction_id , i.e. by patient_laterality\n",
    "sub = pred_df.groupby('prediction_id')[['cancer_raw']].agg('mean')\n",
    "\n",
    "# binarize predictions\n",
    "th = np.quantile(sub['cancer_raw'].values,0.97935)\n",
    "sub['cancer'] = (sub['cancer_raw'].values > th).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5a831e3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T09:58:17.193176Z",
     "iopub.status.busy": "2023-02-27T09:58:17.191879Z",
     "iopub.status.idle": "2023-02-27T09:58:17.205761Z",
     "shell.execute_reply": "2023-02-27T09:58:17.204397Z"
    },
    "papermill": {
     "duration": 0.055194,
     "end_time": "2023-02-27T09:58:17.209023",
     "exception": false,
     "start_time": "2023-02-27T09:58:17.153829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub[['cancer']].to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a15f75f",
   "metadata": {
    "papermill": {
     "duration": 0.036301,
     "end_time": "2023-02-27T09:58:17.282538",
     "exception": false,
     "start_time": "2023-02-27T09:58:17.246237",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "for debugging purpose we can calculate the pF1 score if we infered on the train data by setting RAM_CHECK=True in the beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "027adf60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T09:58:17.358715Z",
     "iopub.status.busy": "2023-02-27T09:58:17.357443Z",
     "iopub.status.idle": "2023-02-27T09:58:17.392695Z",
     "shell.execute_reply": "2023-02-27T09:58:17.390789Z"
    },
    "papermill": {
     "duration": 0.077447,
     "end_time": "2023-02-27T09:58:17.395692",
     "exception": false,
     "start_time": "2023-02-27T09:58:17.318245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1133195487327874 0.6666666666666665\n"
     ]
    }
   ],
   "source": [
    "if RAM_CHECK:\n",
    "\n",
    "    def pfbeta(labels, predictions, beta):\n",
    "        #official implementation\n",
    "        y_true_count = 0\n",
    "        ctp = 0\n",
    "        cfp = 0\n",
    "\n",
    "        for idx in range(len(labels)):\n",
    "            prediction = min(max(predictions[idx], 0), 1)\n",
    "            if (labels[idx]):\n",
    "                y_true_count += 1\n",
    "                ctp += prediction\n",
    "    #             cfp += 1 - prediction #bugfix\n",
    "            else:\n",
    "                cfp += prediction\n",
    "\n",
    "        beta_squared = beta * beta\n",
    "        c_precision = ctp / (ctp + cfp)\n",
    "        c_recall = ctp / y_true_count\n",
    "        if (c_precision > 0 and c_recall > 0):\n",
    "            result = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall)\n",
    "            return result\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    #aggregate by prediction_id , i.e. by patient_laterality\n",
    "    test_df['prediction_id'] = test_df.apply(lambda x: f'{x.patient_id}_{x.laterality}', 1)\n",
    "    test_df_gr = test_df.groupby('prediction_id')[['cancer']].agg('mean')\n",
    "\n",
    "    # Sort both the same\n",
    "    test_df_gr = test_df_gr.loc[sub.index]\n",
    "\n",
    "    y = test_df_gr['cancer'].values#.astype(np.float32)\n",
    "    y_pred = sub['cancer'].values\n",
    "\n",
    "#     print(y.shape, y_pred.shape)\n",
    "\n",
    "    score = pfbeta(y, y_pred, 1)\n",
    "    print(th, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd0e5db",
   "metadata": {
    "papermill": {
     "duration": 0.036735,
     "end_time": "2023-02-27T09:58:17.468761",
     "exception": false,
     "start_time": "2023-02-27T09:58:17.432026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 446.07438,
   "end_time": "2023-02-27T09:58:20.432834",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-02-27T09:50:54.358454",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
